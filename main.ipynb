{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ff1a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from deepnote import MusicRepr, Constants\n",
    "from importlib import reload\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f0b26",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329ce139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: cp-small-v-simplehead-ae-pop-win1024\n"
     ]
    }
   ],
   "source": [
    "const = Constants(unit=4, num_tempo_bins=20, num_velocity_bins=20)\n",
    "\n",
    "data_config = {\n",
    "    'data_dir' : '/home/soroosh/data/MIDI/pop909/train/',\n",
    "#     'data_dir' : '/home/soroosh/data/MIDI/e-gmd-v1.0.0/midis_processed/',\n",
    "#     'data_dir' : '/home/soroosh/data/MIDI/lmd_processed/',\n",
    "    'const' : const,\n",
    "    'instruments' : ['piano', 'drums'],\n",
    "    'mode' : 'cp',\n",
    "    'max_files' : 10,\n",
    "    'window_len' : 1024,\n",
    "    'pad_value' : 0,\n",
    "    'n_jobs' : 20\n",
    "}\n",
    "\n",
    "name = 'cp-small-v-simplehead-ae-pop-win1024'\n",
    "print('model name:',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b411d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b306347952fd4702903fe82fb512c334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14482"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.data\n",
    "reload(src.data)\n",
    "from src.data import MidiDataset\n",
    "\n",
    "dataset = MidiDataset(**data_config)\n",
    "n = len(dataset)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c8ba290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "t = int(0.1 * n)\n",
    "td, vd = random_split(dataset, [n-t, t])\n",
    "tl = DataLoader(dataset=td, batch_size=16, pin_memory=False, shuffle=True, num_workers=4, collate_fn=dataset.fn)\n",
    "vl = DataLoader(dataset=vd, batch_size=32, pin_memory=False, shuffle=False, num_workers=4, collate_fn=dataset.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9275acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([16, 1023, 8]) cpu\n",
      "X_len torch.Size([16]) cpu\n",
      "labels torch.Size([16, 1023, 8]) cpu\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(tl))\n",
    "for k in b:\n",
    "    print(k, b[k].shape, b[k].device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3944e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e77e9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0002,\n",
       " 'embedding': {'d_model': 256,\n",
       "  'dropout': 0.1,\n",
       "  'max_len': 10000,\n",
       "  'positional_embedding': 'relative',\n",
       "  'attributes': ['ttype',\n",
       "   'barbeat',\n",
       "   'tempo',\n",
       "   'chord',\n",
       "   'inst_family',\n",
       "   'pitch',\n",
       "   'duration',\n",
       "   'velocity'],\n",
       "  'n_tokens': {'ttype': 2,\n",
       "   'barbeat': 16,\n",
       "   'tempo': 21,\n",
       "   'chord': 133,\n",
       "   'inst_family': 17,\n",
       "   'pitch': 128,\n",
       "   'duration': 16,\n",
       "   'velocity': 20},\n",
       "  'emb_sizes': {'ttype': 8,\n",
       "   'barbeat': 32,\n",
       "   'tempo': 32,\n",
       "   'chord': 128,\n",
       "   'inst_family': 32,\n",
       "   'pitch': 128,\n",
       "   'duration': 32,\n",
       "   'velocity': 32}},\n",
       " 'head': {'d_model': 256,\n",
       "  'attributes': ['ttype',\n",
       "   'barbeat',\n",
       "   'tempo',\n",
       "   'chord',\n",
       "   'inst_family',\n",
       "   'pitch',\n",
       "   'duration',\n",
       "   'velocity'],\n",
       "  'n_tokens': {'ttype': 2,\n",
       "   'barbeat': 16,\n",
       "   'tempo': 21,\n",
       "   'chord': 133,\n",
       "   'inst_family': 17,\n",
       "   'pitch': 128,\n",
       "   'duration': 16,\n",
       "   'velocity': 20},\n",
       "  'emb_sizes': {'ttype': 8,\n",
       "   'barbeat': 32,\n",
       "   'tempo': 32,\n",
       "   'chord': 128,\n",
       "   'inst_family': 32,\n",
       "   'pitch': 128,\n",
       "   'duration': 32,\n",
       "   'velocity': 32}},\n",
       " 'transformer': {'d_model': 256,\n",
       "  'n_layer': 4,\n",
       "  'n_head': 8,\n",
       "  'd_inner': 256,\n",
       "  'dropout': 0.1,\n",
       "  'activation': 'gelu'},\n",
       " 'attributes': ['ttype',\n",
       "  'barbeat',\n",
       "  'tempo',\n",
       "  'chord',\n",
       "  'inst_family',\n",
       "  'pitch',\n",
       "  'duration',\n",
       "  'velocity']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.config\n",
    "reload(src.config)\n",
    "from src.config import make_config\n",
    "from transformers import GPT2Config, TransfoXLConfig\n",
    "\n",
    "\n",
    "config = make_config(\n",
    "    const,\n",
    "    mode='cp',\n",
    "    model='transformer',\n",
    "    d_model=256, \n",
    "    max_len=10000,\n",
    "    dropout=0.1, \n",
    "    lr=2e-4,\n",
    "    tie_emb=False,\n",
    "    pos_emb='relative', \n",
    "    n_layer=4, \n",
    "    n_head=8, \n",
    "    d_inner=256, \n",
    "    activation='gelu'\n",
    ")\n",
    "\n",
    "# config = make_config(\n",
    "#     const,\n",
    "#     mode='remi',\n",
    "#     model='transformer',\n",
    "#     d_model=256, \n",
    "#     max_len=10000,\n",
    "#     dropout=0.1, \n",
    "#     lr=2e-4,\n",
    "#     tie_emb=False,\n",
    "#     pos_emb='relative', \n",
    "#     n_layer=4, \n",
    "#     n_head=8, \n",
    "#     d_inner=256, \n",
    "#     activation='gelu'\n",
    "# )\n",
    "\n",
    "# config = {\n",
    "#     'lr' : 1e-4,\n",
    "#     'transformer': TransfoXLConfig(\n",
    "#         vocab_size=len(const.all_tokens) + 1,\n",
    "#         cutoffs=[],\n",
    "#         d_model=256,\n",
    "#         d_embed=256,\n",
    "#         d_head=32,\n",
    "#         n_head=8,\n",
    "#         d_inner=256,\n",
    "#         n_layer=4,\n",
    "#         dropout=0.1,\n",
    "#         clamp_len=512,\n",
    "#         pad_token_id=len(const.all_tokens),\n",
    "#         eos_token_id=1,\n",
    "#         bos_token_id=0\n",
    "#     )\n",
    "# }\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63ce98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1818929"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.models.remi import RemiLinearTransformer, RemiHFTransformer, RemiTransformer\n",
    "from src.models.cp import CPSimpleTransformer\n",
    "\n",
    "# model = CPSimpleTransformer(config)\n",
    "model = CPSimpleTransformer.load_from_checkpoint(f'weights/{name}/last.ckpt', config=config)\n",
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb87f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:396: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(save_dir='logs/', name=name)\n",
    "lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=f'weights/{name}/', \n",
    "    filename='{epoch}-{val_loss:.2f}', \n",
    "    monitor='train_loss',\n",
    "    save_top_k=5, \n",
    "    period=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    benchmark=True, \n",
    "    gpus=1, \n",
    "    accumulate_grad_batches=1,\n",
    "    logger=logger, \n",
    "    max_epochs=10,\n",
    "    callbacks=[checkpoint, lr_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae643bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_func   | CrossEntropyLoss   | 0     \n",
      "1 | embedding   | CPEmbedding        | 145 K \n",
      "2 | transformer | VanillaTransformer | 1.6 M \n",
      "3 | head        | CPSimpleHead       | 90.7 K\n",
      "---------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1e35010b3f4160ab4ba22d287013d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, tl, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75f44afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(f'weights/{name}/last.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a68fe",
   "metadata": {},
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "582b811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.models.remi import RemiHFTransformer, RemiTransformer\n",
    "from src.models.cp import CPLinearTransformer, CPTransformer, CPSimpleTransformer\n",
    "\n",
    "\n",
    "gen_model = CPSimpleTransformer.load_from_checkpoint(f\"weights/{name}/last.ckpt\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8ce4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  51\n",
      "['piano']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78, 78)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = data_config['data_dir']\n",
    "import random\n",
    "idx = random.randint(0, 1600)\n",
    "print('idx: ', idx)\n",
    "seq = MusicRepr.from_file(path + os.listdir(path)[idx], const=const)\n",
    "tracks = seq.separate_tracks()\n",
    "tracks = dict([(k,v) for k,v in tracks.items() if k in ['piano']])\n",
    "seq = MusicRepr.merge_tracks(tracks)\n",
    "print(seq.get_instruments())\n",
    "prompt = MusicRepr.concatenate(seq.get_bars()[:5])\n",
    "len(prompt), len(prompt.to_cp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae7a5009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f5d60554cb4eb8bb09369ee698f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(178, 8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_conf = {\n",
    "    'p_ttype' : 1.,\n",
    "    't_ttype' : .2,\n",
    "    'p_barbeat' : 1.,\n",
    "    't_barbeat' : .5,\n",
    "    'p_tempo' : 1.,\n",
    "    't_tempo' : .5,\n",
    "    'p_chord' : 1.,\n",
    "    't_chord' : .5,\n",
    "    'p_inst_family' : 1.,\n",
    "    't_inst_family' : 0.5,\n",
    "    'p_pitch' : 1.,\n",
    "    't_pitch' : .5,\n",
    "    'p_duration' : 1.,\n",
    "    't_duration' : .5,\n",
    "    'p_velocity' : 1.,\n",
    "    't_velocity' : .5,\n",
    "}\n",
    "\n",
    "\n",
    "gen_cp = gen_model.generate(prompt=prompt, max_len=100, window=500, cuda=True, gen_conf=gen_conf)\n",
    "gen_cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "670c9e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 74)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_seq = MusicRepr.from_cp(gen_cp.astype(int), const=const)\n",
    "len(gen_seq), gen_seq.get_bar_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c45b6827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bar(position=0, tempo=115),\n",
       " Beat(position=11),\n",
       " Note(inst_family=piano, pitch=66, duration=2, velocity=67),\n",
       " Note(inst_family=piano, pitch=71, duration=2, velocity=73),\n",
       " Note(inst_family=piano, pitch=68, duration=3, velocity=67),\n",
       " Beat(position=14),\n",
       " Note(inst_family=piano, pitch=75, duration=1, velocity=73),\n",
       " Note(inst_family=piano, pitch=66, duration=5, velocity=60),\n",
       " Note(inst_family=piano, pitch=71, duration=5, velocity=54),\n",
       " Note(inst_family=piano, pitch=63, duration=5, velocity=54),\n",
       " Note(inst_family=piano, pitch=59, duration=9, velocity=54),\n",
       " Bar(position=0, tempo=101),\n",
       " Beat(position=3),\n",
       " Note(inst_family=piano, pitch=66, duration=4, velocity=54),\n",
       " Note(inst_family=piano, pitch=71, duration=4, velocity=60),\n",
       " Beat(position=4),\n",
       " Note(inst_family=piano, pitch=63, duration=3, velocity=47),\n",
       " Beat(position=7),\n",
       " Note(inst_family=piano, pitch=63, duration=3, velocity=54),\n",
       " Note(inst_family=piano, pitch=66, duration=3, velocity=54),\n",
       " Note(inst_family=piano, pitch=71, duration=3, velocity=60),\n",
       " Beat(position=11),\n",
       " Note(inst_family=piano, pitch=63, duration=3, velocity=47),\n",
       " Note(inst_family=piano, pitch=66, duration=3, velocity=60),\n",
       " Note(inst_family=piano, pitch=71, duration=3, velocity=54),\n",
       " Beat(position=15),\n",
       " Note(inst_family=piano, pitch=63, duration=3, velocity=54),\n",
       " Note(inst_family=piano, pitch=66, duration=3, velocity=60),\n",
       " Note(inst_family=piano, pitch=71, duration=4, velocity=60),\n",
       " Bar(position=0, tempo=86, chord=B_M7)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_seq[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6106f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_remi = gen_model.generate(prompt=None, max_len=1000, window=500, cuda=True, top_p=.9, temperature=.7)\n",
    "# print(gen_remi.shape)\n",
    "\n",
    "# tokens = [const.all_tokens[idx] for idx in gen_remi]\n",
    "# print(tokens[:10])\n",
    "# gen_seq = MusicRepr.from_string(' '.join(tokens), const=const)\n",
    "# len(gen_seq), gen_seq.get_bar_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea4a9700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticks per beat: 480\n",
       "max tick: 136320\n",
       "tempo changes: 13\n",
       "time sig: 1\n",
       "key sig: 0\n",
       "markers: 9\n",
       "lyrics: False\n",
       "instruments: 1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_seq.to_midi('cp-v-piano.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68b1e8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6c30873700>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(gen_seq.to_pianoroll(add_tempo_chord=False)['piano'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c3e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
