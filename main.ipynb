{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ff1a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from deepnote import MusicRepr, Constants\n",
    "from importlib import reload\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f0b26",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329ce139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: cp-small-v-pop-win1024\n"
     ]
    }
   ],
   "source": [
    "const = Constants(unit=4, num_tempo_bins=20, num_velocity_bins=20)\n",
    "\n",
    "data_config = {\n",
    "    'data_dir' : '/home/soroosh/data/MIDI/pop909/train/',\n",
    "#     'data_dir' : '/home/soroosh/data/MIDI/e-gmd-v1.0.0/midis_processed/',\n",
    "#     'data_dir' : '/home/soroosh/data/MIDI/lmd_processed/',\n",
    "    'const' : const,\n",
    "    'instruments' : ['piano', 'drums'],\n",
    "    'mode' : 'cp',\n",
    "    'max_files' : 10,\n",
    "    'window_len' : 1024,\n",
    "    'pad_value' : 0,\n",
    "    'n_jobs' : 20\n",
    "}\n",
    "\n",
    "name = 'cp-small-v-pop-win1024'\n",
    "print('model name:',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b411d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc714c4f018d425a95a5788d36db36dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15734"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.data\n",
    "reload(src.data)\n",
    "from src.data import MidiDataset\n",
    "\n",
    "dataset = MidiDataset(**data_config)\n",
    "n = len(dataset)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8ba290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "t = int(0.1 * n)\n",
    "td, vd = random_split(dataset, [n-t, t])\n",
    "tl = DataLoader(dataset=td, batch_size=16, pin_memory=False, shuffle=True, num_workers=4, collate_fn=dataset.fn)\n",
    "vl = DataLoader(dataset=vd, batch_size=32, pin_memory=False, shuffle=False, num_workers=4, collate_fn=dataset.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9275acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([16, 1023, 8]) cpu\n",
      "X_len torch.Size([16]) cpu\n",
      "labels torch.Size([16, 1023, 8]) cpu\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(tl))\n",
    "for k in b:\n",
    "    print(k, b[k].shape, b[k].device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3944e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e77e9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0002,\n",
       " 'embedding': {'d_model': 256,\n",
       "  'dropout': 0.1,\n",
       "  'max_len': 10000,\n",
       "  'positional_embedding': 'relative',\n",
       "  'attributes': ['ttype',\n",
       "   'barbeat',\n",
       "   'tempo',\n",
       "   'chord',\n",
       "   'inst_family',\n",
       "   'pitch',\n",
       "   'duration',\n",
       "   'velocity'],\n",
       "  'n_tokens': {'ttype': 2,\n",
       "   'barbeat': 16,\n",
       "   'tempo': 21,\n",
       "   'chord': 133,\n",
       "   'inst_family': 17,\n",
       "   'pitch': 128,\n",
       "   'duration': 16,\n",
       "   'velocity': 20},\n",
       "  'emb_sizes': {'ttype': 8,\n",
       "   'barbeat': 32,\n",
       "   'tempo': 32,\n",
       "   'chord': 128,\n",
       "   'inst_family': 32,\n",
       "   'pitch': 128,\n",
       "   'duration': 32,\n",
       "   'velocity': 32}},\n",
       " 'head': {'d_model': 256,\n",
       "  'attributes': ['ttype',\n",
       "   'barbeat',\n",
       "   'tempo',\n",
       "   'chord',\n",
       "   'inst_family',\n",
       "   'pitch',\n",
       "   'duration',\n",
       "   'velocity'],\n",
       "  'n_tokens': {'ttype': 2,\n",
       "   'barbeat': 16,\n",
       "   'tempo': 21,\n",
       "   'chord': 133,\n",
       "   'inst_family': 17,\n",
       "   'pitch': 128,\n",
       "   'duration': 16,\n",
       "   'velocity': 20},\n",
       "  'emb_sizes': {'ttype': 8,\n",
       "   'barbeat': 32,\n",
       "   'tempo': 32,\n",
       "   'chord': 128,\n",
       "   'inst_family': 32,\n",
       "   'pitch': 128,\n",
       "   'duration': 32,\n",
       "   'velocity': 32}},\n",
       " 'transformer': {'d_model': 256,\n",
       "  'n_layer': 4,\n",
       "  'n_head': 8,\n",
       "  'd_inner': 256,\n",
       "  'dropout': 0.1,\n",
       "  'activation': 'gelu'},\n",
       " 'attributes': ['ttype',\n",
       "  'barbeat',\n",
       "  'tempo',\n",
       "  'chord',\n",
       "  'inst_family',\n",
       "  'pitch',\n",
       "  'duration',\n",
       "  'velocity']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.config\n",
    "reload(src.config)\n",
    "from src.config import make_config\n",
    "from transformers import GPT2Config, TransfoXLConfig\n",
    "\n",
    "\n",
    "config = make_config(\n",
    "    const,\n",
    "    mode='cp',\n",
    "    model='transformer',\n",
    "    d_model=256, \n",
    "    max_len=10000,\n",
    "    dropout=0.1, \n",
    "    lr=2e-4,\n",
    "    tie_emb=False,\n",
    "    pos_emb='relative', \n",
    "    n_layer=4, \n",
    "    n_head=8, \n",
    "    d_inner=256, \n",
    "    activation='gelu'\n",
    ")\n",
    "\n",
    "# config = make_config(\n",
    "#     const,\n",
    "#     mode='remi',\n",
    "#     model='transformer',\n",
    "#     d_model=256, \n",
    "#     max_len=10000,\n",
    "#     dropout=0.1, \n",
    "#     lr=2e-4,\n",
    "#     tie_emb=False,\n",
    "#     pos_emb='relative', \n",
    "#     n_layer=4, \n",
    "#     n_head=8, \n",
    "#     d_inner=256, \n",
    "#     activation='gelu'\n",
    "# )\n",
    "\n",
    "# config = {\n",
    "#     'lr' : 1e-4,\n",
    "#     'transformer': TransfoXLConfig(\n",
    "#         vocab_size=len(const.all_tokens) + 1,\n",
    "#         cutoffs=[],\n",
    "#         d_model=256,\n",
    "#         d_embed=256,\n",
    "#         d_head=32,\n",
    "#         n_head=8,\n",
    "#         d_inner=256,\n",
    "#         n_layer=4,\n",
    "#         dropout=0.1,\n",
    "#         clamp_len=512,\n",
    "#         pad_token_id=len(const.all_tokens),\n",
    "#         eos_token_id=1,\n",
    "#         bos_token_id=0\n",
    "#     )\n",
    "# }\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ce98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1818929"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from src.models.remi import RemiLinearTransformer, RemiHFTransformer, RemiTransformer\n",
    "from src.models.cp import CPSimpleTransformer\n",
    "\n",
    "model = CPSimpleTransformer(config)\n",
    "# model = RemiTransformer.load_from_checkpoint(f'weights/{name}/last.ckpt', config=config)\n",
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb87f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:396: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(save_dir='logs/', name=name)\n",
    "lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=f'weights/{name}/', \n",
    "    filename='{epoch}-{val_loss:.2f}', \n",
    "    monitor='train_loss',\n",
    "    save_top_k=5, \n",
    "    period=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    benchmark=True, \n",
    "    gpus=1, \n",
    "    accumulate_grad_batches=1,\n",
    "    logger=logger, \n",
    "    max_epochs=100,\n",
    "    callbacks=[checkpoint, lr_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae643bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_func   | CrossEntropyLoss   | 0     \n",
      "1 | embedding   | CPEmbedding        | 145 K \n",
      "2 | transformer | VanillaTransformer | 1.6 M \n",
      "3 | head        | CPSimpleHead       | 90.7 K\n",
      "---------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed09957d53c74a8187333ff9536ecae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, tl, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f44afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(f'weights/{name}/last.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a68fe",
   "metadata": {},
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.models.remi import RemiHFTransformer, RemiTransformer\n",
    "from src.models.cp import CPLinearTransformer, CPTransformer\n",
    "\n",
    "\n",
    "gen_model = CPTransformer.load_from_checkpoint(f\"weights/{name}/last.ckpt\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = data_config['data_dir']\n",
    "# import random\n",
    "# idx = random.randint(0, 21000)\n",
    "# print('idx: ', idx)\n",
    "# seq = MusicRepr.from_file(path + os.listdir(path)[idx], const=const)\n",
    "# tracks = seq.separate_tracks()\n",
    "# tracks = dict([(k,v) for k,v in tracks.items() if k in ['piano', 'drums']])\n",
    "# seq = MusicRepr.merge_tracks(tracks)\n",
    "# print(seq.get_instruments())\n",
    "# prompt = MusicRepr.concatenate(seq.get_bars()[:10])\n",
    "# len(prompt), len(prompt.to_remi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_conf = {\n",
    "    'p_ttype' : 1.,\n",
    "    't_ttype' : .8,\n",
    "    'p_barbeat' : .8,\n",
    "    't_barbeat' : .8,\n",
    "    'p_tempo' : .8,\n",
    "    't_tempo' : .8,\n",
    "    'p_chord' : .8,\n",
    "    't_chord' : .8,\n",
    "    'p_inst_family' : 0.8,\n",
    "    't_inst_family' : 0.8,\n",
    "    'p_pitch' : .8,\n",
    "    't_pitch' : .8,\n",
    "    'p_duration' : .8,\n",
    "    't_duration' : .8,\n",
    "    'p_velocity' : .8,\n",
    "    't_velocity' : .8,\n",
    "}\n",
    "\n",
    "gen_cp = gen_model.generate(prompt=None, max_len=500, window=500, cuda=True, gen_conf=gen_conf)\n",
    "gen_cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_seq = MusicRepr.from_cp(gen_cp.astype(int), const=const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_remi = gen_model.generate(prompt=None, max_len=1000, window=500, cuda=True, top_p=.9, temperature=.7)\n",
    "# print(gen_remi.shape)\n",
    "\n",
    "# tokens = [const.all_tokens[idx] for idx in gen_remi]\n",
    "# print(tokens[:10])\n",
    "# gen_seq = MusicRepr.from_string(' '.join(tokens), const=const)\n",
    "# len(gen_seq), gen_seq.get_bar_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_seq.to_midi('cp-v-drums.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc98374",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gen_seq), gen_seq.get_bar_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(gen_seq.to_pianoroll(add_tempo_chord=False)['drums'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c3e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
